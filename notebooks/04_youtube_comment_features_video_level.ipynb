{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b01858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_PATH: c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\02_comment_features\\youtube_comments_kr_v1.csv\n",
      "OUT_COMMENT_LEVEL: c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\02_comment_features\\youtube_comment_features_comment_level_kr_v1.csv\n",
      "OUT_VIDEO_LEVEL  : c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\02_comment_features\\youtube_comment_features_video_level_kr_v1.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    p = Path.cwd()\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / \"data\").exists() and (parent / \"notebooks\").exists():\n",
    "            return parent\n",
    "    return p\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "ACCUM_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"01_daily_accumulated\"\n",
    "FEAT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"02_comment_features\"\n",
    "FEAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 입력(우선순위): 한국어 필터 결과 → 없으면 raw 누적본\n",
    "IN_KO = FEAT_DIR / \"youtube_comments_kr_v1.csv\"\n",
    "IN_RAW = ACCUM_DIR / \"youtube_comments_raw_kr_v1.csv\"\n",
    "IN_PATH = IN_KO if IN_KO.exists() else IN_RAW\n",
    "\n",
    "OUT_COMMENT_LEVEL = FEAT_DIR / \"youtube_comment_features_comment_level_kr_v1.csv\"\n",
    "OUT_VIDEO_LEVEL   = FEAT_DIR / \"youtube_comment_features_video_level_kr_v1.csv\"\n",
    "\n",
    "print(\"IN_PATH:\", IN_PATH)\n",
    "print(\"OUT_COMMENT_LEVEL:\", OUT_COMMENT_LEVEL)\n",
    "print(\"OUT_VIDEO_LEVEL  :\", OUT_VIDEO_LEVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9f6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved comment_level: c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\02_comment_features\\youtube_comment_features_comment_level_kr_v1.csv | rows: 4428\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(IN_PATH, low_memory=False)\n",
    "\n",
    "need = [\"video_id\",\"comment_id\",\"author_channel_id\",\"published_at\",\"like_count\",\"text\"]\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"입력 파일에 필요한 컬럼이 없습니다: {missing}\\nIN_PATH={IN_PATH}\")\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).fillna(\"\").str.strip()\n",
    "df[\"video_id\"] = df[\"video_id\"].astype(str).str.strip()\n",
    "\n",
    "url_re = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "hashtag_re = re.compile(r\"#\\w+\")\n",
    "mention_re = re.compile(r\"@\\w+\")\n",
    "hangul_re = re.compile(r\"[가-힣]\")\n",
    "\n",
    "def count_pat(pattern, s: str) -> int:\n",
    "    if not isinstance(s, str) or not s:\n",
    "        return 0\n",
    "    return len(pattern.findall(s))\n",
    "\n",
    "def hangul_ratio(s: str) -> float:\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return 0.0\n",
    "    chars = [c for c in s if c.strip()]\n",
    "    if not chars:\n",
    "        return 0.0\n",
    "    h = sum(1 for c in chars if hangul_re.search(c))\n",
    "    return h / len(chars)\n",
    "\n",
    "comment_level = df[[\"video_id\", \"comment_id\", \"author_channel_id\", \"published_at\", \"like_count\", \"text\"]].copy()\n",
    "comment_level[\"text_len\"] = comment_level[\"text\"].str.len()\n",
    "comment_level[\"url_cnt\"] = comment_level[\"text\"].apply(lambda x: count_pat(url_re, x))\n",
    "comment_level[\"hashtag_cnt\"] = comment_level[\"text\"].apply(lambda x: count_pat(hashtag_re, x))\n",
    "comment_level[\"mention_cnt\"] = comment_level[\"text\"].apply(lambda x: count_pat(mention_re, x))\n",
    "comment_level[\"hangul_ratio\"] = comment_level[\"text\"].apply(hangul_ratio)\n",
    "comment_level[\"is_korean_like\"] = (comment_level[\"hangul_ratio\"] >= 0.15).astype(int)\n",
    "\n",
    "# 저장(선택 출력)\n",
    "comment_level.to_csv(OUT_COMMENT_LEVEL, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved comment_level:\", OUT_COMMENT_LEVEL, \"| rows:\", len(comment_level))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15dcf38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved video_level: c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\02_comment_features\\youtube_comment_features_video_level_kr_v1.csv | rows: 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unique_authors</th>\n",
       "      <th>mean_like_count</th>\n",
       "      <th>mean_text_len</th>\n",
       "      <th>url_ratio</th>\n",
       "      <th>hashtag_ratio</th>\n",
       "      <th>mention_ratio</th>\n",
       "      <th>korean_comment_ratio</th>\n",
       "      <th>mean_hangul_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-WGFbInX6JI</td>\n",
       "      <td>190</td>\n",
       "      <td>178</td>\n",
       "      <td>4.352632</td>\n",
       "      <td>36.226316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0HXwT4gefnQ</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>25.471698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.824822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5y1YQx1g4Mg</td>\n",
       "      <td>192</td>\n",
       "      <td>178</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>26.302083</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6BRMs8EH1Co</td>\n",
       "      <td>199</td>\n",
       "      <td>175</td>\n",
       "      <td>1.638191</td>\n",
       "      <td>27.185930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80kIVHdpT_w</td>\n",
       "      <td>199</td>\n",
       "      <td>193</td>\n",
       "      <td>3.678392</td>\n",
       "      <td>32.045226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  comment_count  unique_authors  mean_like_count  mean_text_len  \\\n",
       "0  -WGFbInX6JI            190             178         4.352632      36.226316   \n",
       "1  0HXwT4gefnQ             53              53         0.094340      25.471698   \n",
       "2  5y1YQx1g4Mg            192             178         1.166667      26.302083   \n",
       "3  6BRMs8EH1Co            199             175         1.638191      27.185930   \n",
       "4  80kIVHdpT_w            199             193         3.678392      32.045226   \n",
       "\n",
       "   url_ratio  hashtag_ratio  mention_ratio  korean_comment_ratio  \\\n",
       "0   0.000000            0.0       0.000000                   1.0   \n",
       "1   0.000000            0.0       0.000000                   1.0   \n",
       "2   0.005208            0.0       0.005208                   1.0   \n",
       "3   0.000000            0.0       0.000000                   1.0   \n",
       "4   0.000000            0.0       0.000000                   1.0   \n",
       "\n",
       "   mean_hangul_ratio  \n",
       "0           0.732096  \n",
       "1           0.824822  \n",
       "2           0.744385  \n",
       "3           0.747631  \n",
       "4           0.817846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_level = (\n",
    "    comment_level\n",
    "    .groupby(\"video_id\", as_index=False)\n",
    "    .agg(\n",
    "        comment_count=(\"comment_id\", \"count\"),\n",
    "        unique_authors=(\"author_channel_id\", pd.Series.nunique),\n",
    "        mean_like_count=(\"like_count\", \"mean\"),\n",
    "        mean_text_len=(\"text_len\", \"mean\"),\n",
    "        url_ratio=(\"url_cnt\", lambda x: (x > 0).mean()),\n",
    "        hashtag_ratio=(\"hashtag_cnt\", lambda x: (x > 0).mean()),\n",
    "        mention_ratio=(\"mention_cnt\", lambda x: (x > 0).mean()),\n",
    "        korean_comment_ratio=(\"is_korean_like\", \"mean\"),\n",
    "        mean_hangul_ratio=(\"hangul_ratio\", \"mean\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "video_level[\"mean_like_count\"] = video_level[\"mean_like_count\"].fillna(0)\n",
    "video_level.to_csv(OUT_VIDEO_LEVEL, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved video_level:\", OUT_VIDEO_LEVEL, \"| rows:\", len(video_level))\n",
    "\n",
    "display(video_level.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
