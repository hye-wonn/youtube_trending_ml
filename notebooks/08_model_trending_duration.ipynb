{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7358ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 데이터 파일 경로 (프로젝트 상대경로)\n",
    "# ----------------------------\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    p = Path.cwd()\n",
    "\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / \"data\").exists() and (parent / \"notebooks\").exists():\n",
    "            return parent\n",
    "\n",
    "    return p\n",
    "\n",
    "def latest_versioned_csv(folder: Path, base_name: str) -> Optional[Path]:\n",
    "    pattern = re.compile(rf\"^{re.escape(base_name)}_v(\\d+)\\.csv$\")\n",
    "    best_v, best_path = None, None\n",
    "\n",
    "    for f in folder.glob(f\"{base_name}_v*.csv\"):\n",
    "        m = pattern.match(f.name)\n",
    "\n",
    "        if m:\n",
    "            v = int(m.group(1))\n",
    "\n",
    "            if best_v is None or v > best_v:\n",
    "                best_v, best_path = v, f\n",
    "\n",
    "    return best_path\n",
    "\n",
    "def next_versioned_file(folder: Path, base_name: str, ext: str = \".csv\") -> Path:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pattern = re.compile(rf\"^{re.escape(base_name)}_v(\\d+){re.escape(ext)}$\")\n",
    "    versions = []\n",
    "\n",
    "    for f in folder.glob(f\"{base_name}_v*{ext}\"):\n",
    "        m = pattern.match(f.name)\n",
    "\n",
    "        if m:\n",
    "            versions.append(int(m.group(1)))\n",
    "\n",
    "    v = (max(versions) + 1) if versions else 1\n",
    "    return folder / f\"{base_name}_v{v}{ext}\"\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "\n",
    "CLEAN_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "csv_path = latest_versioned_csv(CLEAN_DIR, \"trending_videos_clean\")\n",
    "if csv_path is None:\n",
    "    csv_path = CLEAN_DIR / \"trending_videos_clean_v1.csv\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"csv_path:\", csv_path)\n",
    "\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f\"트렌딩 clean 파일이 없습니다: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "print(\"데이터 로드 완료, shape:\", df.shape)\n",
    "print(\"컬럼 목록:\", list(df.columns))\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 공통: 독립변수(feature) 구성\n",
    "# =====================================================\n",
    "\n",
    "base_feature_cols = [\n",
    "    \"view_count\",\n",
    "    \"likes\",\n",
    "    \"comment_count\",\n",
    "    \"categoryId\",\n",
    "    \"publish_dayofweek\",\n",
    "    \"tags_count\",\n",
    "]\n",
    "\n",
    "# 실제로 존재하는 컬럼만 사용\n",
    "feature_cols = [c for c in base_feature_cols if c in df.columns]\n",
    "print(\"\\n사용 독립변수 (feature_cols):\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# 함수: 회귀 평가 출력\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def eval_regression(name, y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"R²  :\", r2)\n",
    "    \n",
    "    return rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 영상 분석 모델링\n",
    "# =====================================================\n",
    "\n",
    "# 타깃: trending_days (회귀)\n",
    "if \"trending_days\" not in df.columns:\n",
    "    raise ValueError(\"trending_days 컬럼이 없습니다. v2 파일을 확인해주세요.\")\n",
    "\n",
    "df_trend = df.dropna(subset=[\"trending_days\"]).copy()\n",
    "\n",
    "X1 = df_trend[feature_cols].fillna(0)\n",
    "y1 = df_trend[\"trending_days\"].fillna(0)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "    X1, y1, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n[1번] trending_days 모델링용 데이터 분할 완료\")\n",
    "print(\"Train:\", X1_train.shape, \"/ Test:\", X1_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d32671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Decision Tree Regressor\n",
    "# =====================================================\n",
    "\n",
    "tree = DecisionTreeRegressor(\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "tree.fit(X1_train, y1_train)\n",
    "y1_pred_tree = tree.predict(X1_test)\n",
    "eval_regression(\"Decision Tree Regressor (trending_days)\", y1_test, y1_pred_tree)\n",
    "\n",
    "tree_importance = pd.DataFrame(\n",
    "    {\"feature\": X1.columns, \"importance\": tree.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[Decision Tree - 변수 중요도]\")\n",
    "print(tree_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Random Forest Regressor\n",
    "# =====================================================\n",
    "\n",
    "rf1 = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf1.fit(X1_train, y1_train)\n",
    "y1_pred_rf = rf1.predict(X1_test)\n",
    "eval_regression(\"Random Forest Regressor (trending_days)\", y1_test, y1_pred_rf)\n",
    "\n",
    "rf1_importance = pd.DataFrame(\n",
    "    {\"feature\": X1.columns, \"importance\": rf1.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[Random Forest - 변수 중요도]\")\n",
    "print(rf1_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# XGBoost Regressor\n",
    "# =====================================================\n",
    "\n",
    "xgb1 = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "xgb1.fit(X1_train, y1_train)\n",
    "y1_pred_xgb = xgb1.predict(X1_test)\n",
    "eval_regression(\"XGBoost Regressor (trending_days)\", y1_test, y1_pred_xgb)\n",
    "\n",
    "xgb1_importance = pd.DataFrame(\n",
    "    {\"feature\": X1.columns, \"importance\": xgb1.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[XGBoost - 변수 중요도]\")\n",
    "print(xgb1_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# [Table 1] trending_days 회귀 모델 성능 비교\n",
    "# =====================================================\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mae, rmse, r2\n",
    "\n",
    "mae_tree, rmse_tree, r2_tree = regression_metrics(y1_test, y1_pred_tree)\n",
    "mae_rf, rmse_rf, r2_rf = regression_metrics(y1_test, y1_pred_rf)\n",
    "mae_xgb, rmse_xgb, r2_xgb = regression_metrics(y1_test, y1_pred_xgb)\n",
    "\n",
    "table1_results = pd.DataFrame({\n",
    "    \"Model\": [\"Decision Tree\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"MAE\": [mae_tree, mae_rf, mae_xgb],\n",
    "    \"RMSE\": [rmse_tree, rmse_rf, rmse_xgb],\n",
    "    \"R²\": [r2_tree, r2_rf, r2_xgb],\n",
    "})\n",
    "\n",
    "table1_results[[\"MAE\", \"RMSE\", \"R²\"]] = table1_results[[\"MAE\", \"RMSE\", \"R²\"]].round(4)\n",
    "table1_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93063491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 회귀: engagement_score\n",
    "# =====================================================\n",
    "\n",
    "if \"engagement_score\" not in df.columns:\n",
    "    raise ValueError(\"engagement_score 컬럼이 없습니다. v2 파일을 확인해주세요.\")\n",
    "\n",
    "df_eng = df.dropna(subset=[\"engagement_score\"]).copy()\n",
    "\n",
    "X2 = df_eng[feature_cols].fillna(0)\n",
    "y2 = df_eng[\"engagement_score\"].fillna(0)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    X2, y2, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n[2번-회귀] engagement_score 회귀용 데이터 분할 완료\")\n",
    "print(\"Train:\", X2_train.shape, \"/ Test:\", X2_test.shape)\n",
    "\n",
    "# Decision Tree\n",
    "tree2 = DecisionTreeRegressor(\n",
    "    max_depth=8, min_samples_leaf=50, random_state=42\n",
    ")\n",
    "\n",
    "tree2.fit(X2_train, y2_train)\n",
    "y2_pred_tree = tree2.predict(X2_test)\n",
    "eval_regression(\"Decision Tree Regressor (engagement_score)\", y2_test, y2_pred_tree)\n",
    "\n",
    "tree2_importance = pd.DataFrame(\n",
    "    {\"feature\": X2.columns, \"importance\": tree2.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[Decision Tree(engagement_score) - 변수 중요도]\")\n",
    "print(tree2_importance)\n",
    "\n",
    "# Random Forest\n",
    "rf2 = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf2.fit(X2_train, y2_train)\n",
    "y2_pred_rf = rf2.predict(X2_test)\n",
    "eval_regression(\"Random Forest Regressor (engagement_score)\", y2_test, y2_pred_rf)\n",
    "\n",
    "rf2_importance = pd.DataFrame(\n",
    "    {\"feature\": X2.columns, \"importance\": rf2.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[Random Forest(engagement_score) - 변수 중요도]\")\n",
    "print(rf2_importance)\n",
    "\n",
    "# XGBoost\n",
    "xgb2 = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "xgb2.fit(X2_train, y2_train)\n",
    "y2_pred_xgb = xgb2.predict(X2_test)\n",
    "eval_regression(\"XGBoost Regressor (engagement_score)\", y2_test, y2_pred_xgb)\n",
    "\n",
    "xgb2_importance = pd.DataFrame(\n",
    "    {\"feature\": X2.columns, \"importance\": xgb2.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[XGBoost(engagement_score) - 변수 중요도]\")\n",
    "print(xgb2_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d91029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 분류: high_engagement\n",
    "# =====================================================\n",
    "\n",
    "# 상위 20% 기준으로 high_engagement 라벨 생성\n",
    "threshold = df_eng[\"engagement_score\"].quantile(0.8)\n",
    "df_eng[\"high_engagement\"] = (df_eng[\"engagement_score\"] >= threshold).astype(int)\n",
    "\n",
    "print(\"\\nhigh_engagement threshold (상위 20%):\", threshold)\n",
    "print(df_eng[\"high_engagement\"].value_counts())\n",
    "\n",
    "X3 = df_eng[feature_cols].fillna(0)\n",
    "y3 = df_eng[\"high_engagement\"]\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
    "    X3, y3, test_size=0.2, random_state=42, stratify=y3\n",
    ")\n",
    "\n",
    "print(\"\\n[2번-분류] high_engagement 분류용 데이터 분할 완료\")\n",
    "print(\"Train:\", X3_train.shape, \"/ Test:\", X3_test.shape)\n",
    "\n",
    "# RandomForest Classifier\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf_clf.fit(X3_train, y3_train)\n",
    "y3_pred_rf = rf_clf.predict(X3_test)\n",
    "\n",
    "print(\"\\n[RandomForest Classifier 결과 (high_engagement)]\")\n",
    "print(classification_report(y3_test, y3_pred_rf))\n",
    "\n",
    "print(\"\\n[Confusion Matrix]\")\n",
    "print(confusion_matrix(y3_test, y3_pred_rf))\n",
    "\n",
    "rf_clf_importance = pd.DataFrame(\n",
    "    {\"feature\": X3.columns, \"importance\": rf_clf.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[RandomForest Classifier - 변수 중요도]\")\n",
    "print(rf_clf_importance)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X3_train, y3_train)\n",
    "y3_pred_xgb = xgb_clf.predict(X3_test)\n",
    "\n",
    "print(\"\\n[XGBoost Classifier 결과 (high_engagement)]\")\n",
    "print(classification_report(y3_test, y3_pred_xgb))\n",
    "\n",
    "xgb_clf_importance = pd.DataFrame(\n",
    "    {\"feature\": X3.columns, \"importance\": xgb_clf.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n[XGBoost Classifier - 변수 중요도]\")\n",
    "print(xgb_clf_importance)\n",
    "\n",
    "print(\"\\n1번(트렌딩 유지기간) + 2번(참여도 회귀/분류) 핵심 모델링 완료!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
