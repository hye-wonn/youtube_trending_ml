{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f9323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_PATH: c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\01_daily_accumulated\\youtube_comments_raw_kr_v1.csv\n",
      "OUT_KO_PATH: c:\\Users\\73bib\\Desktop\\유혜원\\제주한라대학교\\[2025] 프로젝트\\bigdata_project\\youtube_trending_ml\\data\\processed\\02_comment_features\\youtube_comments_kr_v1.csv\n",
      "✅ raw rows: 5714\n",
      "✅ ko rows : 4428\n",
      "✅ saved columns: ['video_id', 'comment_id', 'author_channel_id', 'published_at', 'like_count', 'text', 'run_ts_utc', 'collected_date', 'updated_at', 'author_display_name']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# ✅ 프로젝트 루트 자동 탐색 + 경로\n",
    "# =========================\n",
    "def find_project_root() -> Path:\n",
    "    p = Path.cwd()\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / \"data\").exists() and (parent / \"notebooks\").exists():\n",
    "            return parent\n",
    "    return p\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "ACCUM_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"01_daily_accumulated\"\n",
    "OUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"02_comment_features\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_PATH = ACCUM_DIR / \"youtube_comments_raw_kr_v1.csv\"\n",
    "OUT_KO_PATH = OUT_DIR / \"youtube_comments_kr_v1.csv\"\n",
    "\n",
    "print(\"IN_PATH:\", IN_PATH)\n",
    "print(\"OUT_KO_PATH:\", OUT_KO_PATH)\n",
    "\n",
    "# =========================\n",
    "# ✅ 간단 한국어 판별 함수\n",
    "# =========================\n",
    "hangul_re = re.compile(r\"[가-힣]\")\n",
    "\n",
    "def is_korean_text(text: str, threshold: float = 0.15) -> bool:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return False\n",
    "    chars = [c for c in text if c.strip()]\n",
    "    if not chars:\n",
    "        return False\n",
    "    hangul_cnt = sum(1 for c in chars if hangul_re.search(c))\n",
    "    return (hangul_cnt / len(chars)) >= threshold\n",
    "\n",
    "# =========================\n",
    "# ✅ 로드\n",
    "# =========================\n",
    "df = pd.read_csv(IN_PATH, low_memory=False)\n",
    "\n",
    "# =========================\n",
    "# ✅ (핵심) 중복 컬럼 표준화: likeCount/like_count, comment_publishedAt/published_at\n",
    "# =========================\n",
    "# like_count: like_count 우선, 없으면 likeCount 사용\n",
    "if \"like_count\" not in df.columns and \"likeCount\" in df.columns:\n",
    "    df[\"like_count\"] = df[\"likeCount\"]\n",
    "elif \"like_count\" in df.columns and \"likeCount\" in df.columns:\n",
    "    # 둘 다 있으면 like_count를 기준으로 하고, 비어있는 곳만 likeCount로 채움\n",
    "    df[\"like_count\"] = df[\"like_count\"].fillna(df[\"likeCount\"])\n",
    "\n",
    "# published_at: published_at 우선, 없으면 comment_publishedAt 사용\n",
    "if \"published_at\" not in df.columns and \"comment_publishedAt\" in df.columns:\n",
    "    df[\"published_at\"] = df[\"comment_publishedAt\"]\n",
    "elif \"published_at\" in df.columns and \"comment_publishedAt\" in df.columns:\n",
    "    df[\"published_at\"] = df[\"published_at\"].fillna(df[\"comment_publishedAt\"])\n",
    "\n",
    "# =========================\n",
    "# ✅ 타입/클린업\n",
    "# =========================\n",
    "for c in [\"video_id\", \"comment_id\", \"author_channel_id\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).fillna(\"\").str.strip()\n",
    "\n",
    "df[\"text\"] = df.get(\"text\", \"\").astype(str).fillna(\"\").str.strip()\n",
    "\n",
    "# 숫자형\n",
    "df[\"like_count\"] = pd.to_numeric(df.get(\"like_count\", 0), errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 날짜형(문자열 유지해도 되지만, 최소 정규화)\n",
    "df[\"published_at\"] = pd.to_datetime(df.get(\"published_at\", pd.NaT), errors=\"coerce\")\n",
    "\n",
    "# =========================\n",
    "# ✅ 한국어 필터\n",
    "# =========================\n",
    "df[\"is_korean\"] = df[\"text\"].apply(is_korean_text)\n",
    "df_ko = df[df[\"is_korean\"]].copy()\n",
    "\n",
    "# =========================\n",
    "# ✅ 출력 컬럼: 04가 요구하는 표준 컬럼 중심으로 제한 (혼동 방지)\n",
    "# =========================\n",
    "keep_cols = [\n",
    "    \"video_id\",\n",
    "    \"comment_id\",\n",
    "    \"author_channel_id\",\n",
    "    \"published_at\",\n",
    "    \"like_count\",\n",
    "    \"text\",\n",
    "    # 아래는 있으면 같이 보관(재현/추적용) — 필요 없으면 지워도 됨\n",
    "    \"run_id\",\n",
    "    \"country\",\n",
    "    \"run_ts_utc\",\n",
    "    \"collected_date\",\n",
    "    \"updated_at\",\n",
    "    \"author_display_name\",\n",
    "    \"category_name\",\n",
    "]\n",
    "keep_cols = [c for c in keep_cols if c in df_ko.columns]\n",
    "df_ko = df_ko[keep_cols]\n",
    "\n",
    "# published_at을 문자열로 저장(Excel/CSV 호환)\n",
    "if \"published_at\" in df_ko.columns:\n",
    "    df_ko[\"published_at\"] = df_ko[\"published_at\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "df_ko.to_csv(OUT_KO_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ raw rows:\", len(df))\n",
    "print(\"✅ ko rows :\", len(df_ko))\n",
    "print(\"✅ saved columns:\", df_ko.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
